# PokÃ©mon ETL con Airflow, Docker y PostgreSQL

Este proyecto implementa un **pipeline ETL** que extrae datos desde la [PokeAPI](https://pokeapi.co/), los transforma y los carga en **PostgreSQL**, ademÃ¡s de generar un archivo **Parquet** y **CSV** para anÃ¡lisis. El flujo se orquesta con **Apache Airflow** y estÃ¡ totalmente contenerizado con **Docker**.

---

## **CaracterÃ­sticas**
- ExtracciÃ³n asÃ­ncrona de datos de PokÃ©mon y especies desde PokeAPI.
- TransformaciÃ³n de datos en **pandas** y guardado en **Parquet** (Snappy) y CSV.
- Carga a **PostgreSQL** mediante SQLAlchemy.
- ConfiguraciÃ³n centralizada en `config.json`.
- EjecuciÃ³n manual o mediante DAG de **Airflow**.
- **Docker Compose** para levantar Airflow, PostgreSQL y el contenedor ETL.
- GestiÃ³n de dependencias con **Poetry**.

## ðŸ“‚ **Estructura del proyecto**
```
pokemon_etl/
â”œâ”€â”€ docker-compose.yaml         # OrquestaciÃ³n de servicios
â”œâ”€â”€ pyproject.toml              # Dependencias (Poetry)
â”œâ”€â”€ dags/                       # DAG de Airflow
â”‚   â””â”€â”€ pokemon_dags.py
â”œâ”€â”€ src/pokemon_etl/            # CÃ³digo ETL
â”‚   â”œâ”€â”€ config_manager.py
â”‚   â”œâ”€â”€ extract.py
â”‚   â”œâ”€â”€ transform.py
â”‚   â”œâ”€â”€ load.py
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ config_file/config.json     # ConfiguraciÃ³n del pipeline
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Datos crudos (API)
â”‚   â””â”€â”€ processed/              # Datos procesados (Parquet y CSV)
â”œâ”€â”€ logs/                       # Logs de ejecuciÃ³n
â””â”€â”€ notebooks/                  # Experimentos Jupyter
```

## **TecnologÃ­as**
- **Python** 3.11
- **Poetry** para la gestiÃ³n de dependencias
- **Apache Airflow**
- **Docker & Docker Compose**
- **PostgreSQL**
- **pandas**, **pyarrow**, **aiohttp**, **SQLAlchemy**

---

## **ConfiguraciÃ³n**
Variables clave en `config_file/config.json`:
```json
"db_config": {
  "db_name": "pokemon_db",
  "user": "myuser",
  "password": "mypassword",
  "host": "pokemon-db",
  "port": 5432
}
```

En **Airflow**:
- Variables: rutas y nombres de archivo.
- Connection: `postgres_pokemon` con credenciales de DB.

---

## **InstalaciÃ³n y ejecuciÃ³n**
Clona el repositorio:
```bash
git clone https://github.com/tuusuario/pokemon_etl.git
cd pokemon_etl
```

### **1. Ejecutar con Docker Compose**
Levanta Airflow + PostgreSQL + ETL:
```bash
docker-compose up --build
```
Accede a Airflow en:  
`http://localhost:8080`  
Usuario y clave por defecto: `airflow / airflow`

Activa el DAG: **pokemon_etl_dag**.

### **2. Ejecutar localmente**
Instala dependencias:
```bash
poetry install
```
Ejecuta el pipeline:
```bash
poetry run python src/pokemon_etl/__init__.py
```

## **Salida**
- **Archivo Parquet**: `data/processed/pokemones.parquet`
- **Archivo CSV**: `data/processed/pokemones.csv`
- **Tabla en PostgreSQL**: `pokemons`